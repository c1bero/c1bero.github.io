---
layout: single
classes: wide
title:  "TFCCTF 25: Slots"
date:   2025-09-14 14:00:00 +0200
---

Two weeks ago I had a nice BBQ with some friends and we decided to play the TFCCTF 2025 while enjoying the delicious food.

I looked at the Slots challenge which is a Linux kernel pwn challenge. It's a nice challenge because the kernel module is small but contains multiple
vulnerabilities. In particular, it is affected by a use-after-free (UAF) vulnerability which is ideal for exploitation demonstrations. Thus, I was
thinking: Instead of exploiting one of the vulnerabilities to get the flag as quickly as possible, let's revisit an arbitrary read/write technique using
pipe buffers to become root, although this is not required for the challenge.

Since the UAF vulnerability is easily triggerable, one can focus on applying the exploitation technique involving pipe buffers. I am talking about
[pipe_buffer arbitrary read write](https://www.interruptlabs.co.uk/articles/pipe-buffer).

If someone wants to learn about this technique and needs a minimal vulnerable kernel module as a playground, the Slots challenge is a nice place to
go!

You can find all given files of the challenge as well as my exploit in my [GitHub repository](https://github.com/c1bero/tfcctf-2025).

Enough talking, let's dive into it!

## Challenge

We are given the following typical files for a Linux kernel pwn challenge:

```
$ ls
bzImage  initramfs  initramfs.cpio.gz  run.sh  vmlinux
```

The `run.sh` script looks as follows:

```
$ cat run.sh
#!/bin/sh

qemu-system-x86_64 \
  -kernel ./bzImage \
  -cpu max \
  -initrd ./initramfs.cpio.gz \
  -nographic \
  -monitor none,server,nowait,nodelay,reconnect=-1 \
  -serial stdio  \
  -display none \
  -m 256M \
  -no-reboot \
  -nographic \
  -append "console=ttyS0 kpti fgkaslr quiet"%
```

Note that the VM only gets 256M RAM.

Unpacking the `initramfs.cpio.gz` file gives us the following filesystem:

```
bin  dev  etc  flag  home  init  linuxrc  mnt  proc  sbin  slot_machine.ko  sys  usr
```

Here are three interesting files:

* The `flag` file which contains the flag to find.
* The `slot_machine.ko` kernel module which we must exploit in this challenge.
* The `init` script.

Let's inspect the `init` script.

```sh
#!/bin/sh

export PS1='\[\033[01;32m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]\$ '
export LD_LIBRARY_PATH=/lib

chown -R root:root /
chmod 0700 /root
chown -R noob:noob /home/noob

mkdir -p /proc && mount -t proc none /proc
mkdir -p /dev  && mount -t devtmpfs devtmpfs /dev
mkdir -p /tmp  && mount -t tmpfs tmpfs /tmp
mkdir -p /sys && mount -t sysfs none /sys
mkdir -p /dev/pts && mount -t devpts /dev/ptmx /dev/pts

insmod slot_machine.ko
chmod 666 /dev/slot_machine

sysctl -w kernel.modprobe=""
sysctl -w kernel.core_pattern=""
echo 1 | tee /proc/sys/kernel/modules_disabled
echo 0 | tee /proc/sys/kernel/usermodehelper/bset
echo 0 | tee /proc/sys/kernel/usermodehelper/inheritable
echo "" | tee /sys/kernel/uevent_helper  >/dev/null

rm flag
echo -e "\nBoot took $(cut -d' ' -f1 /proc/uptime) seconds\n"

exec su -s /bin/sh - noob

poweroff -d 0 -f
```

In summary, the `init` script loads the `slot_machine.ko` kernel module, removes the `flag` file, and gives us a shell in the context of the `noob`
user. After executing the `run.sh` script, we can see that the Linux kernel version 6.15.0 is running:

```
~ $ id
uid=1000(noob) gid=1000(noob) groups=1000(noob)
~ $ uname -a
Linux (none) 6.15.0+ #2 SMP Thu Jun  5 19:58:09 EEST 2025 x86_64 GNU/Linux
```

Since the `flag` file is removed, the `slot_machine.ko` module probably processes it before deletion, so we may still be able to read it. Let's check.

For readers, who are not so familiar with Linux kernel CTF challenges, I highly recommend the writeup
[Learning Linux Kernel Exploitation - Part 1](https://lkmidas.github.io/posts/20210123-linux-kernel-pwn-part-1/). It explains how to
decompress/recompress the filesystem, how to get the exploit into the VM, and more.

## Code Analysis

Let's analyze the two functions `module_init()` and `my_ioctl()` which we obtained by decompiling the `slot_machine.ko` kernel module with IDA:

```c
unsigned __int64 module_init()
{
  unsigned __int64 result; // rax
  __int64 v1; // rbx
  unsigned __int64 v2; // r12
  signed __int64 v3; // rax
  unsigned int v4; // [rsp+0h] [rbp-120h]
  __int64 v5; // [rsp+8h] [rbp-118h] BYREF
  _BYTE src[272]; // [rsp+10h] [rbp-110h] BYREF

  v5 = 0LL;

[1]

  result = _register_chrdev(0LL, 0LL, 256LL, "slot_machine", &fops);
  major = result;
  if ( (result & 0x80000000) == 0LL )
  {
    my_class = class_create("slot_machine");
    if ( (unsigned __int64)my_class > 0xFFFFFFFFFFFFF000LL )
    {
      _unregister_chrdev((unsigned int)major, 0LL, 256LL, "slot_machine");
      return (unsigned int)my_class;
    }
    else
    {

[2]

      my_device = device_create(my_class, 0LL, (unsigned int)(major << 20), 0LL, "slot_machine");
      if ( (unsigned __int64)my_device > 0xFFFFFFFFFFFFF000LL )
      {
        class_destroy(my_class);
        _unregister_chrdev((unsigned int)major, 0LL, 256LL, "slot_machine");
        return (unsigned int)my_device;
      }
      else
      {
        v1 = 0LL;

[3]

        result = filp_open("/flag", 0LL, 0LL);
        v2 = result;
        if ( result <= 0xFFFFFFFFFFFFF000LL )
        {
          while ( 1 )
          {
            flag_size = v1;
            v3 = kernel_read(v2, src, 255LL, &v5);
            if ( v3 <= 0 )
              break;
            v1 = flag_size + v3;
            if ( (unsigned __int64)(flag_size + v3) > 0x400 )
            {
              filp_close(v2, 0LL, v3);
              return 4294967284LL;
            }

[4]

            memcpy(&flag_data[flag_size], src, v3);
          }
          if ( v3 )
          {
            v4 = v3;
            filp_close(v2, 0LL, v3);
            return v4;
          }
          else
          {
            flag_data[flag_size] = 0;
            filp_close(v2, 0LL, 0LL);
            printk(&unk_3D0, "slot_machine");
            return 0LL;
          }
        }
      }
    }
  }
  return result;
}
```

At [1], the `slot_machine` character device is registered. The actual device node in `/dev/slot_machine` is created at [2].

The `flag` file containing the flag is opened at [3] which is then written to `flag_data` in the `.bss` segment of `slot_machine` at [4].

The goal of this challenge will be reading the flag from `flag_data`.

Next, let's see how to interact with this device through IOCTL calls.

```c
__int64 __fastcall my_ioctl(__int64 a1, unsigned int a2, __int64 a3)
{
  __int64 v4; // [rsp+0h] [rbp-18h] BYREF
  unsigned __int64 v5; // [rsp+8h] [rbp-10h]
  __int64 v6; // [rsp+10h] [rbp-8h]

  if ( a2 == 3 )
  {
    if ( copy_from_user(&v4, a3, 24LL) )
      return -14LL;
    if ( !chunk || v4 + v5 > chunk_size )
      return -22LL;
    if ( v5 > 0x7FFFFFFF )
      goto LABEL_26;

[5]

    if ( !copy_from_user(v4 + chunk, v6, v5) )
      return 0LL;
    return -14LL;
  }
  if ( a2 > 3 )
  {
    if ( a2 != 1337 )
      return 0LL;
    if ( !copy_from_user(&v4, a3, 24LL) )
    {
      if ( chunk && v4 + v5 <= chunk_size )
      {
        if ( v5 <= 0x7FFFFFFF )
        {

[6]

          if ( copy_to_user(v6, v4 + chunk) )
            return -14LL;
          return 0LL;
        }
LABEL_26:
        BUG();
      }
      return -22LL;
    }
    return -14LL;
  }
  if ( a2 )
  {
    if ( a2 == 1 )
    {
      if ( chunk )

[7]

        kfree(chunk, a3);
    }
    return 0LL;
  }
  if ( chunk_allocated_times > 1 )
    return -22LL;
  if ( copy_from_user(&v4, a3, 8LL) )
    return -14LL;

[8]

  chunk = _kmalloc_noprof(v4, 3264LL);
  if ( !chunk )
    return -12LL;
  ++chunk_allocated_times;
  chunk_size = v4;
  return 0LL;
}
```

We can send four different IOCTL request codes:

* Request code 0 to allocate memory on the kernel heap with `_kmalloc_noprof()` at [8]. A pointer to this allocated memory is stored in the global `chunk` variable.
* Request code 1 to free `chunk` at [7].
* Request code 3 to write user controlled data to chunk at [5].
* Request code 1337 to read `chunk` at [6].

The `my_ioctl()` function contains multiple vulnerabilities.

Since `v4` is declared as a signed integer (instead of an unsigned one), an attacker can provide a negative value for `v4` (which is a large unsigned
value) such that the check `v4 + v5 <= chunk_size` before [6] can be bypassed and one can read out-of-bounds. This vulnerability could probably be
used to read the flag from the `.bss` segment of `slot_machine`. However, we do not want to focus on this vulnerability in this writeup.

Instead, let's exploit the following use-after-free vulnerability. Note that freeing `chunk` at [7] doesn't set the `chunk` pointer to `NULL`. Thus,
it is possible to write to `chunk` at [5] and read from `chunk` at [6] after `chunk` was freed.

## Exploitation

This is a really strong UAF vulnerability since we can write to `chunk` and read from `chunk` as often as we want to after we have freed it. Moreover, we
can freely choose the size with which `chunk` is allocated at [8].

The roadmap for exploiting this UAF vulnerability to become root is as follows:

* Get an arbitrary read/write primitive by performing the pipe buffer technique explained [here](https://www.interruptlabs.co.uk/articles/pipe-buffer) by InterruptLabs.
* Use the arbitrary read primitive to find the location of our task's credentials.
* Use the arbitrary write primitive to escalate our privileges to root by overwriting our task's credentials.

Since the `/flag` file was deleted by the `init` script, we cannot just read it as the root user. Thus, in order to also complete this challenge we

* Apply the arbitrary read primitive to read the flag.

### Replacing chunk by a pipe buffer

The general idea of exploiting a UAF vulnerability is as follows:

* One is given a dangling pointer (here `chunk`) to a freed memory region. Dependent on the specific vulnerability, one can read from/write to the
  freed memory region partially or completely. Let's call this memory region victim chunk.
* The dangling pointer assumes an object of `type 1` in the victim chunk.
* One triggers the allocation of another object such that this object is placed into the victim chunk. This new object has the `type 2`.
* Now the dangling pointer operates under the assumption that an object of `type 1` is in the victim chunk while an object of `type 2` is. This is a
  "type confusion".
* If the `type 2` is a "useful" object type, one can manipulate this object to gain a nice exploitation primitive.

This general concept brings up some questions:

1) When are objects of different types allocated "at the same address"? More specifically: When is an object of `type 2` allocated at the address of the victim chunk?
2) What is a "useful" object type?

As regards question 1), there exist different kind of slab caches whose meta information can be seen in `/proc/slabinfo`:

```
~ # cat /proc/slabinfo
slabinfo - version: 2.1
# name            <active_objs> <num_objs> <objsize> <objperslab> <pagesperslab> : tunables <limit> <batchcount> <sharedfactor> : slabdata <active_slabs> <num_slabs> <sharedavail>
io_kiocb               0      0    256   16    1 : tunables    0    0    0 : slabdata      0      0      0

[Truncated]

filp                  21     21    192   21    1 : tunables    0    0    0 : slabdata      1      1      0
inode_cache           14     14    560   14    2 : tunables    0    0    0 : slabdata      1      1      0
dentry               567    672    192   21    1 : tunables    0    0    0 : slabdata     32     32      0

[Truncated]

vmap_area            112    112     72   56    1 : tunables    0    0    0 : slabdata      2      2      0
dma-kmalloc-8k         0      0   8192    4    8 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-4k         0      0   4096    8    8 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-2k         0      0   2048    8    4 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-1k         0      0   1024    8    2 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-512        0      0    512    8    1 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-256        0      0    256   16    1 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-128        0      0    128   32    1 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-64         0      0     64   64    1 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-32         0      0     32  128    1 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-16         0      0     16  256    1 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-8          0      0      8  512    1 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-192        0      0    192   21    1 : tunables    0    0    0 : slabdata      0      0      0
dma-kmalloc-96         0      0     96   42    1 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-8k         0      0   8192    4    8 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-4k         0      0   4096    8    8 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-2k         0      0   2048    8    4 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-1k         0      0   1024    8    2 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-512        0      0    512    8    1 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-256        0      0    256   16    1 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-128        0      0    128   32    1 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-64         0      0     64   64    1 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-32         0      0     32  128    1 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-16         0      0     16  256    1 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-8          0      0      8  512    1 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-192        0      0    192   21    1 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-rcl-96         0      0     96   42    1 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-8k             0      0   8192    4    8 : tunables    0    0    0 : slabdata      0      0      0
kmalloc-4k             8      8   4096    8    8 : tunables    0    0    0 : slabdata      1      1      0
kmalloc-2k            32     32   2048    8    4 : tunables    0    0    0 : slabdata      4      4      0
kmalloc-1k            32     32   1024    8    2 : tunables    0    0    0 : slabdata      4      4      0
kmalloc-512          200    200    512    8    1 : tunables    0    0    0 : slabdata     25     25      0
kmalloc-256          160    160    256   16    1 : tunables    0    0    0 : slabdata     10     10      0
kmalloc-128          192    192    128   32    1 : tunables    0    0    0 : slabdata      6      6      0
kmalloc-64           256    256     64   64    1 : tunables    0    0    0 : slabdata      4      4      0
kmalloc-32           512    512     32  128    1 : tunables    0    0    0 : slabdata      4      4      0
kmalloc-16           256    256     16  256    1 : tunables    0    0    0 : slabdata      1      1      0
kmalloc-8           1024   1024      8  512    1 : tunables    0    0    0 : slabdata      2      2      0
kmalloc-192          126    126    192   21    1 : tunables    0    0    0 : slabdata      6      6      0
kmalloc-96           168    168     96   42    1 : tunables    0    0    0 : slabdata      4      4      0
kmem_cache_node      128    128     64   64    1 : tunables    0    0    0 : slabdata      2      2      0
kmem_cache            96     96    256   16    1 : tunables    0    0    0 : slabdata      6      6      0
```

I don't want to go into too much detail here. Roughly said, there exist dedicated caches like `filp` and general purpose caches like `kmalloc-8` and
`kmalloc-16`. When calling `void *kmalloc(size_t size, gfp_t flags)`, it depends on the `flags` allocation context, which kind of general purpose
cache is used, e.g. `kmalloc-x` or `kmalloc-rcl-x` in the current kernel configuration. The `size` parameter determines the specific slab cache within
the allocation context, e.g. a chunk of size `(32, 64]` is taken from `kmalloc-64` while a chunk of size `(64, 96]` is taken from `kmalloc-96`.

A nice introduction of the memory allocator, page allocator, and slab allocator can be found here:

* [Linternals: Introducing Memory Allocators & The Page Allocator](https://sam4k.com/linternals-memory-allocators-part-1)
* [Linternals: The Slab Allocator](https://sam4k.com/linternals-memory-allocators-0x02/)
* [A Quick Dive Into The Linux Kernel Page Allocator](https://syst3mfailure.io/linux-page-allocator/)

To inspect these slab caches and find the specific slab cache a chunk is allocated in, I find the gdb plugin
[gef-kernel](https://github.com/destr4ct/gef-kernel) very useful. For example, let's say we send an IOCTL with the request code 0 and the size 72 to
an opened file descriptor of `/dev/slot_machine`, then we can inspect the address returned by `_kmalloc_noprof()` at [8]:

```
gef> slab-contains 0xff11000002214e40
[+] Wait for memory scan
slab: 0xffd4000000088500
kmem_cache: 0xff11000002033200
base: 0xff11000002214000
name: kmalloc-96  size: 0x60  num_pages: 0x1
```

We can see that the chunk was allocated in `kmalloc-96`. Remember that we can freely choose the size of the chunk.

Note: Look at [Patching, Instrumenting & Debugging Linux Kernel Modules](https://sam4k.com/patching-instrumenting-debugging-linux-kernel-modules/) on how to
debug a kernel module like `slot_machine.ko` with gdb.

This brings us back to the above question 2): What is a "useful" object type?

A "useful" object is an object which improves our current primitive. As our current UAF primitive is already really good, a "useful" object would be
one which allows us to write to and read from arbitrary addresses.
Moreover, this "useful" object must be allocated within the same allocation context as the victim chunk.

In this writeup, we will concentrate on objects with the `struct pipe_buffer` type and the technique by
[pipe_buffer arbitrary read write](https://www.interruptlabs.co.uk/articles/pipe-buffer).

When a user creates a pipe, it can be both written to and read from. To store the to-be-written data, the pipe is backed by a page. These features are
reflected by the `struct pipe_buffer` structure:

```c
// https://elixir.bootlin.com/linux/v6.15/source/include/linux/pipe_fs_i.h#L26

/**
 *	struct pipe_buffer - a linux kernel pipe buffer
 *	@page: the page containing the data for the pipe buffer
 *	@offset: offset of data inside the @page
 *	@len: length of data inside the @page
 *	@ops: operations associated with this buffer. See @pipe_buf_operations.
 *	@flags: pipe buffer flags. See above.
 *	@private: private data owned by the ops.
 **/
struct pipe_buffer {
        struct page *page;
        unsigned int offset, len;
        const struct pipe_buf_operations *ops;
        unsigned int flags;
        unsigned long private;
};
```

The above structure has a size of 36 bytes. Let's see how and when such a structure is created in the kernel.

When we create a pipe by invoking `pipe()` from userland, a `struct pipe_inode_info` structure is initialized by the kernel:

```c
// https://elixir.bootlin.com/linux/v6.15/source/include/linux/pipe_fs_i.h#L86

/**
 *	struct pipe_inode_info - a linux kernel pipe
 *	@mutex: mutex protecting the whole thing
 *	@rd_wait: reader wait point in case of empty pipe
 *	@wr_wait: writer wait point in case of full pipe
 *	@head: The point of buffer production
 *	@tail: The point of buffer consumption
 *	@head_tail: unsigned long union of @head and @tail
 *	@note_loss: The next read() should insert a data-lost message
 *	@max_usage: The maximum number of slots that may be used in the ring
 *	@ring_size: total number of buffers (should be a power of 2)
 *	@nr_accounted: The amount this pipe accounts for in user->pipe_bufs
 *	@tmp_page: cached released page
 *	@readers: number of current readers of this pipe
 *	@writers: number of current writers of this pipe
 *	@files: number of struct file referring this pipe (protected by ->i_lock)
 *	@r_counter: reader counter
 *	@w_counter: writer counter
 *	@poll_usage: is this pipe used for epoll, which has crazy wakeups?
 *	@fasync_readers: reader side fasync
 *	@fasync_writers: writer side fasync
 *	@bufs: the circular array of pipe buffers
 *	@user: the user who created this pipe
 *	@watch_queue: If this pipe is a watch_queue, this is the stuff for that
 **/
struct pipe_inode_info {
        struct mutex mutex;
        wait_queue_head_t rd_wait, wr_wait;

        /* This has to match the 'union pipe_index' above */
        union {
                unsigned long head_tail;
                struct {
                        pipe_index_t head;
                        pipe_index_t tail;
                };
        };

        unsigned int max_usage;
        unsigned int ring_size;
        unsigned int nr_accounted;
        unsigned int readers;
        unsigned int writers;
        unsigned int files;
        unsigned int r_counter;
        unsigned int w_counter;
        bool poll_usage;
#ifdef CONFIG_WATCH_QUEUE
        bool note_loss;
#endif
        struct page *tmp_page[2];
        struct fasync_struct *fasync_readers;
        struct fasync_struct *fasync_writers;
        struct pipe_buffer *bufs;
        struct user_struct *user;
#ifdef CONFIG_WATCH_QUEUE
        struct watch_queue *watch_queue;
#endif
};
```

The above structure contains the `struct pipe_buffer *bufs` member which is a circular array of pipe buffers. Let `n` denote a power of 2, then
`fcntl(pipe_fd, F_SETPIPE_SZ, PAGE_SIZE * n)` results in allocating a buffer of size `n * sizeof(struct pipe_buffer) = n * 36` for the above `bufs`
circular array of pipe buffers. For example, `fcntl(pipe_fd, F_SETPIPE_SZ, 4096 * 2)` leads to the allocation of a buffer of size `2 * 36 = 72` for
the `bufs` member.

In the Linux kernel code this can be seen as follows: Calling `fcntl(pipe_fd, F_SETPIPE_SZ, PAGE_SIZE * n)` from userland leads to the invocation of
the kernel function `pipe_fcntl()`:

```c
// https://elixir.bootlin.com/linux/v6.15/source/fs/pipe.c#L1425
long pipe_fcntl(struct file *file, unsigned int cmd, unsigned int arg)
{
        struct pipe_inode_info *pipe;
        long ret;

        pipe = get_pipe_info(file, false);
        if (!pipe)
                return -EBADF;

        mutex_lock(&pipe->mutex);

        switch (cmd) {
        case F_SETPIPE_SZ:

[9]

                ret = pipe_set_size(pipe, arg);
                break;
        case F_GETPIPE_SZ:
                ret = pipe->max_usage * PAGE_SIZE;
                break;
        default:
                ret = -EINVAL;
                break;
        }

        mutex_unlock(&pipe->mutex);
        return ret;
}
```

At [9], `pipe_set_size()` is called where `arg = PAGE_SIZE * n`:

```c
// https://elixir.bootlin.com/linux/v6.15/source/fs/pipe.c#L1361

/*
 * Allocate a new array of pipe buffers and copy the info over. Returns the
 * pipe size if successful, or return -ERROR on error.
 */
static long pipe_set_size(struct pipe_inode_info *pipe, unsigned int arg)
{
        unsigned long user_bufs;
        unsigned int nr_slots, size;
        long ret = 0;

        if (pipe_has_watch_queue(pipe))
                return -EBUSY;

[10]

        size = round_pipe_size(arg);
        nr_slots = size >> PAGE_SHIFT;

        if (!nr_slots)
                return -EINVAL;

[Truncated]

[11]

        ret = pipe_resize_ring(pipe, nr_slots);
        if (ret < 0)
                goto out_revert_acct;

        return pipe->max_usage * PAGE_SIZE;

out_revert_acct:
        (void) account_pipe_buffers(pipe->user, nr_slots, pipe->nr_accounted);
        return ret;
}
```

Since both `PAGE_SIZE = 4096` and `n` are powers of 2, `arg = PAGE_SIZE * n` is a power of 2, too. As `round_pipe_size()` rounds `arg` up to a power
of 2, `size` is set to `arg = PAGE_SIZE * n` at [10]. Noting that `PAGE_SIZE = 1 << PAGE_SHIFT`, we have that

```
nr_slots
= size >> PAGE_SHIFT
= ( (1 << PAGE_SHIFT) * n) >> PAGE_SHIFT
= n
```

Then, at [11], `pipe_resize_ring()` is called with the `nr_slots = n` argument.

```c
// https://elixir.bootlin.com/linux/v6.15/source/fs/pipe.c#L1288

/*
 * Resize the pipe ring to a number of slots.
 *
 * Note the pipe can be reduced in capacity, but only if the current
 * occupancy doesn't exceed nr_slots; if it does, EBUSY will be
 * returned instead.
 */
int pipe_resize_ring(struct pipe_inode_info *pipe, unsigned int nr_slots)
{
        struct pipe_buffer *bufs;
        unsigned int head, tail, mask, n;

        /* nr_slots larger than limits of pipe->{head,tail} */
        if (unlikely(nr_slots > (pipe_index_t)-1u))
                return -EINVAL;

[12]

        bufs = kcalloc(nr_slots, sizeof(*bufs),
                       GFP_KERNEL_ACCOUNT | __GFP_NOWARN);

[Truncated]

        return 0;
}
```

At [12], `kcalloc()` is invoked to allocate a buffer of size `nr_slots * sizeof(struct pipe_buffer)` with the `gfp_mask` flags
`GFP_KERNEL_ACCOUNT | __GFP_NOWARN`. In our example `n=2`, a buffer of size `2 * 36 = 72` is allocated. If `CONFIG_MEMCG_KMEM` was enabled, this
would lead to an allocation in `kmalloc-cg-96`. However, since this config is not set, a buffer in `kmalloc-96` is allocated. Yeah, this means that
this buffer is allocated in the same slab cache as the victim chunk at [8]!

Therefore, we can indeed reallocate the freed victim chunk with a `struct pipe_buffer` buffer.

Although we don't require the knowledge of the kernel base address in this exploit, one often wants to leak and use it in other exploits. By
exploiting our UAF primitive and read the victim chunk's memory, we can leak a `struct pipe_buffer` object whose `ops` member points to
`anon_pipe_buf_ops`. This is a structure of function pointers which is placed at a kernel address with a fixed offset from the virtual kernel base
address.

However, although we have reallocated the victim chunk with a `struct pipe_buffer`, the pipe buffer members have not been set yet. This will only
happen when we write to the pipe. When we write to a pipe from userland, the `anon_pipe_write()` kernel function is called:

```c
// File: https://elixir.bootlin.com/linux/v6.15/source/fs/pipe.c#L432

static ssize_t
anon_pipe_write(struct kiocb *iocb, struct iov_iter *from)
{
        struct file *filp = iocb->ki_filp;
        struct pipe_inode_info *pipe = filp->private_data;
        unsigned int head;
        ssize_t ret = 0;
        size_t total_len = iov_iter_count(from);
        ssize_t chars;
        bool was_empty = false;
        bool wake_next_writer = false;

[Truncated]

        head = pipe->head;
        was_empty = pipe_empty(head, pipe->tail);
        chars = total_len & (PAGE_SIZE-1);
        if (chars && !was_empty) {

[Truncated]

        }

        for (;;) {
                if (!pipe->readers) {
                        send_sig(SIGPIPE, current, 0);
                        if (!ret)
                                ret = -EPIPE;
                        break;
                }

                head = pipe->head;
                if (!pipe_full(head, pipe->tail, pipe->max_usage)) {
                        struct pipe_buffer *buf;
                        struct page *page;
                        int copied;

                        page = anon_pipe_get_page(pipe);
                        if (unlikely(!page)) {
                                if (!ret)
                                        ret = -ENOMEM;
                                break;
                        }

                        copied = copy_page_from_iter(page, 0, PAGE_SIZE, from);
                        if (unlikely(copied < PAGE_SIZE && iov_iter_count(from))) {
                                anon_pipe_put_page(pipe, page);
                                if (!ret)
                                        ret = -EFAULT;
                                break;
                        }

                        pipe->head = head + 1;

[13]

                        /* Insert it into the buffer array */
                        buf = pipe_buf(pipe, head);
                        buf->page = page;
                        buf->ops = &anon_pipe_buf_ops;
                        buf->offset = 0;
                        if (is_packetized(filp))
                                buf->flags = PIPE_BUF_FLAG_PACKET;
                        else
                                buf->flags = PIPE_BUF_FLAG_CAN_MERGE;

                        buf->len = copied;
                        ret += copied;

                        if (!iov_iter_count(from))
                                break;

                        continue;
                }

[Truncated]

        return ret;
}
```

If the pipe is empty, we can see that the `struct pipe_buffer *buf`'s members are set at [13].

Thus, we can leak the virtual kernel base address as follows (although we do not need the kernel base address in this exploit):

* Allocate a victim chunk of size 72 by sending an IOCTL with the request code 0.
* Free the victim chunk by sending an IOCTL with the request code 1.
* Reclaim the victim chunk with a pipe buffer by calling `pipe()` and `fcntl(pipe_fd, F_SETPIPE_SZ, 4096 * 2)`.
* Write some data to the pipe.
* Read the victim chunk, which now contains a `struct pipe_buffer`, by sending an IOCTL with the request code 1337.
* Based on the leaked `anon_pipe_buf_ops` address, compute the virtual kernel base address.


### Arbitrary Read/Write Primitive

Now that we have reallocated the victim chunk with a pipe buffer and we can read from and write to the pipe, which is associated with this pipe
buffer, let's dive into getting an arbitrary read/write primitive.

We have seen above that we can can leak the content of a `struct pipe_buffer` structure. This means that we have leaked the `page` member of the pipe
buffer, which points to a `struct page` structure. The `struct page` structure has a size of 0x40 bytes and is used by the kernel to represent
physical memory. Thanks to the UAF vulnerability we can still write to the victim chunk where the pipe buffer is currently placed. Thus, we can
overwrite the pipe buffer's `page` member and set it to a value representing phyiscal memory of our choice. Afterwards, reading from/writing to the
pipe would lead to reading from/writing to this physical memory. The question is how to choose the value of the `page` member and what we want to
achieve.

The `struct page` structures representing the physical memory are placed as an array starting at `vmemmap_base`. Thus, each such `struct page` object
can be found at `vmemmap_base + idx * 0x40` for some `idx` integer. Due to KASLR, `vmemmap_base` has a different address each time the kernel boots.
Due to the leaked `page` member of the pipe buffer, we can compute `vmemmap_base` as follows:

```
vmemmap_base = leaked_page & 0xfffffffff0000000
```

Let's say we have a given kernel heap address (call it `heap_addr`) and we want to compute the associated `struct page` address within the `vmemmap`
array. We can accomplish this by the following computation:

```
page = vmemmap_base + ( (heap_addr & 0xfffffff ) >> 12 ) * 0x40
```

I reference again the blog post [pipe_buffer arbitrary read write](https://www.interruptlabs.co.uk/articles/pipe-buffer) by InterruptLabs for more
information. Nevertheless, I would like to add some additional notes. The above computation of the conversion from `heap_addr` to `page` only works
for the current challenge because the challenge's VM only has 256M RAM. One consequence is that the `Normal` zone is empty as can be seen by running
`dmsg`:

```
~ # dmesg | grep -A 5 -i "Zone ranges"
[    0.020644] Zone ranges:
[    0.020664]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
[    0.020713]   DMA32    [mem 0x0000000001000000-0x000000000ffdffff]
[    0.020718]   Normal   empty
[    0.020731] Movable zone start for each node
[    0.020749] Early memory node ranges
```

For experimental purposes, we can increase the RAM in the `run.sh` script from 256M to 4G and run `dmsg` again:

```
~ # dmesg | grep -A 5 -i "Zone ranges"
[    0.030408] Zone ranges:
[    0.030435]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
[    0.030492]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff]
[    0.030497]   Normal   [mem 0x0000000100000000-0x000000013fffffff]
[    0.030504] Movable zone start for each node
[    0.030523] Early memory node ranges
```

In this case, a `Normal` zone is used. In a nutshell, `0x100000000`  is the physical heap base where the buddy allocator starts managing pages. In this
case we would have to change the above computation to the following, which is the one you can find in the blog post by InterruptLabs:

```
page = vmemmap_base + (0x100000000 >> 12) * 0x40) + ( (heap_addr & 0xfffffff ) >> 12 ) * 0x40
```

Now that we know how to convert a kernel heap address into the associated page address, we can exploit our UAF vulnerability to overwrite the pipe buffer in the victim chunk as follows:

Writing to `heap_addr`:

* Set `pipe.page` to the computed page address associated with the `heap_addr`.
* Set `pipe.offset` to the offset of `heap_addr` within its page.
* Set `pipe.len = 0` indicating that no bytes have been written to the pipe yet.
* set `pipe.flags = PIPE_BUF_FLAG_CAN_MERGE`, which means that the data buffer inside the pipe can be merged.

Reading a complete page which contains `heap_addr`:

* Set `pipe.page` to the computed page address associated with the `heap_addr`.
* Set `pipe.offset = 0` if we want to read the complete page (4096 bytes) which contains the data at `heap_addr`.
* Set `pipe.len = 4096 + 1` since we want to read 4096 bytes but want to avoid a release of the page. This member says how many bytes have been
  written to the pipe. We can read at most `pipe.len` many bytes from the pipe. If we read exactly `pipe.len` many bytes, the pipe is drained and the associated
  `struct pipe_buffer` is released which would destroy our UAF primitive.
* set `pipe.flags = PIPE_BUF_FLAG_CAN_MERGE`, which means that the data buffer inside the pipe can be merged.

#### Escalating Privileges

Our first goal is escalating our privileges to root. When we execute our userland exploit program, the kernel creates an underlying
`struct task_struct` structure, which is a fairly large structure and allocated on the kernel's heap. Here is an excerpt of the structure:

```c
// https://elixir.bootlin.com/linux/v6.15/source/include/linux/sched.h#L813

struct task_struct {

[Truncated]

        /* Process credentials: */

        /* Tracer's credentials at attach: */
        const struct cred __rcu		*ptracer_cred;

        /* Objective and real subjective task credentials (COW): */
        const struct cred __rcu		*real_cred;

[14]

        /* Effective (overridable) subjective task credentials (COW): */
        const struct cred __rcu		*cred;

#ifdef CONFIG_KEYS
        /* Cached requested key. */
        struct key			*cached_requested_key;
#endif

        /*
         * executable name, excluding path.
         *
         * - normally initialized begin_new_exec()
         * - set it with set_task_comm()
         *   - strscpy_pad() to ensure it is always NUL-terminated and
         *     zero-padded
         *   - task_lock() to ensure the operation is atomic and the name is
         *     fully updated.
         */

[15]

        char				comm[TASK_COMM_LEN];

[Truncated]

};
```

I want to highlight two members. The `comm` member at [15] is the name of our exploit program. We can change this name by executing
`prctl(PR_SET_NAME, name, 0, 0, 0)`. Therefore, we can set our tasks's name to a specific string value, which is stored somewhere on the kernel's
heap.

Let's assume for a moment that we can find the heap address of our tasks's `comm` member. Then, we can compute the address of our tasks's `cred`
member [14] since its offset to the `comm` member's address is constant. Once we have the `cred` member's address, we can use our arbitrary write primitive
to overwrite the `cred` member's contents, which are our taks's credentials. The `struct cred` structure looks as follows:

```c
// https://elixir.bootlin.com/linux/v6.15/source/include/linux/cred.h#L111

struct cred {
        atomic_long_t   usage;
        kuid_t          uid;            /* real UID of the task */
        kgid_t          gid;            /* real GID of the task */
        kuid_t          suid;           /* saved UID of the task */
        kgid_t          sgid;           /* saved GID of the task */
        kuid_t          euid;           /* effective UID of the task */
        kgid_t          egid;           /* effective GID of the task */
        kuid_t          fsuid;          /* UID for VFS ops */
        kgid_t          fsgid;          /* GID for VFS ops */
        unsigned        securebits;     /* SUID-less security management */
        kernel_cap_t    cap_inheritable; /* caps our children can inherit */
        kernel_cap_t    cap_permitted;  /* caps we're permitted */
        kernel_cap_t    cap_effective;  /* caps we can actually use */
        kernel_cap_t    cap_bset;       /* capability bounding set */
        kernel_cap_t    cap_ambient;    /* Ambient capability set */
#ifdef CONFIG_KEYS
        unsigned char   jit_keyring;	/* default keyring to attach requested
                                         * keys to */
        struct key      *session_keyring; /* keyring inherited over fork */
        struct key      *process_keyring; /* keyring private to this process */
        struct key      *thread_keyring; /* keyring private to this thread */
        struct key      *request_key_auth; /* assumed request_key authority */
#endif
#ifdef CONFIG_SECURITY
        void            *security;      /* LSM security */
#endif
        struct user_struct *user;       /* real user ID subscription */
        struct user_namespace *user_ns; /* user_ns the caps and keyrings are relative to. */
        struct ucounts *ucounts;
        struct group_info *group_info;  /* supplementary groups for euid/fsgid */
        /* RCU deletion */
        union {
                int non_rcu;                    /* Can we skip RCU deletion? */
                struct rcu_head	rcu;            /* RCU deletion hook */
        };
} __randomize_layout;
```

By overwriting all members starting with `uid` and ending with `fsgid` with zeros, our task's credentials become root credentials.

We had assumed that we can find the heap address of our tasks's `comm` member. But how can we do that? Since we have computed `vmemmap_base` above
based on the leaked `page` pointer of a pipe buffer, we can iterate through `vmemmap_base + idx * 0x40` and use our arbitrary read primitive to read
the physical memory represented by `vmemmap_base + idx * 0x40`. In each iteration, we search for our task's `comm` string and perform some additional
checks to make sure that it's the `comm` string of a `struct task_struct` structure.

Nice, now we can become root!

### Reading the Flag

Although we have become root, we still need/want to solve the challenge and find the flag. Recall that the flag is stored in the `.bss` segment of the
loaded `slot_machine` kernel module. We just use the above primitive and iterate through `vmemmap_base + idx * 0x40` until we find the flag identifier
`TFCCTF{` on a page. This was sufficient to find the flag!

### Example Execution

Let's see the exploit in action. It prints the flag and spawns us a beautiful root shell:

```
~ $ id
uid=1000(noob) gid=1000(noob) groups=1000(noob)
~ $ /exploit 
[*] Allocating pipes ...
[*] Writing to each pipe and checking if the victim chunk was reclaimed by a pipe buffer ...
[+] found victim pipe idx: 0
[+] kernel base: ffffffffafc00000
[+] vmemmap_base = 0xffdeb63880000000
[+] found creds: creds = 0xff18f375c1125600, page_creds = 0xffdeb63880044940
[*] Overwriting our task's credentials with zeros...
[+] Became successfully root! getuid() = 0
[*] Coming back to the CTF challenge... Iterating through vmemmap, reading from pages, and looking for the flag ...
[+] Found the flag: TFCCTF{fakeflag}

[+] Now enjoy your root shell :-)
/bin/sh: can't access tty; job control turned off
~ # id
uid=0(root) gid=0(root) groups=1000(noob)
```

## Conclusion

This was a nice Linux kernel pwn challenge with a really strong UAF primitive. This strong and easily triggerable vulnerability allowed us to focus on
an exploitation technique based on pipe buffers to get an arbitrary read/write primitive and become root.
I hope that this writeup will be helpful for some readers in the future when trying to understand and apply this pipe buffer technique.
